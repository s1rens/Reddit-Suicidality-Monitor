{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "Project - Main Program.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1rens/Reddit-Suicidality-Monitor/blob/main/Main_Program.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCU1P7uU3vj5"
      },
      "source": [
        "!pip install praw\n",
        "!pip install cryptography\n",
        "import pandas as pd\n",
        "import praw\n",
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import spacy\n",
        "import pickle\n",
        "import csv\n",
        "import time\n",
        "import os\n",
        "from cryptography.fernet import Fernet\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-bDgBrI3vj_"
      },
      "source": [
        "# Initialising reddit instance\n",
        "reddit = praw.Reddit(client_id='ENTER CLIENT ID', client_secret='ENTER CLIENT SECRET', username='ENTER REDDIT USERNAME', password='ENTER PASSWORD', user_agent='null') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kNenYVC3vkA"
      },
      "source": [
        "# load trained logistic regression model\n",
        "with open ('model_logistic_regression_3000.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "\n",
        "# load trained tfidf vectorizer\n",
        "with open('tfidf_3000.pkl', 'rb') as file:\n",
        "    tfidf = pickle.load(file)\n",
        "\n",
        "# load important words\n",
        "important_words = []\n",
        "with open('important_words_3000.txt', 'r') as file:\n",
        "    important_words.extend(file.read().split('\\n'))\n",
        "    \n",
        "# load inspirational quotes\n",
        "inspirational_quotes = []\n",
        "with open('inspirational_quotes.txt', 'r', encoding='utf-8') as file:\n",
        "    inspirational_quotes.extend(file.read().split('\\n'))\n",
        "\n",
        "# load key for encryting and decrypting\n",
        "with open('key.key', 'rb') as file:\n",
        "        key = file.read()\n",
        "fnet = Fernet(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4cjDO253vkB"
      },
      "source": [
        "# append classified submissions to .csv with row format [subreddit,author,date,text, prediction]\n",
        "def log_submission(submission_df, prediction_df):\n",
        "    try:\n",
        "        submission_df.drop(columns=['postfixed','goodlemma', 'goodlemma_most_important'], inplace=True)\n",
        "        combined = pd.concat([submission_df, prediction_df], ignore_index=True, axis=1)\n",
        "        display(combined)\n",
        "        # append to existing file or create new file if it doesn't exist\n",
        "        with open('submission_log.csv', 'a', newline='') as file: \n",
        "            if file.tell() == 0: # checks if file position is 0 (i.e. if its empty) and writes column headers\n",
        "                file.write('subreddit,author,date,post,prediction\\n')\n",
        "            encrypted = combined.applymap(lambda x: fnet.encrypt(str(x).encode()))\n",
        "            encrypted = encrypted.applymap(lambda x: x.decode())\n",
        "            encrypted.to_csv(file, header=False, index=False)\n",
        "        return combined\n",
        "    except Exception as e:\n",
        "        print('log_submission Error is: ' + str(e))\n",
        "        pass\n",
        "\n",
        "# This is the code for the bot.\n",
        "def bot(updating, combined_df): \n",
        "    ############################################################################################################\n",
        "    # Choose what subject and message to send to users who's post was classified as suicidal\n",
        "    # Can do options so user can pick reply that might help them the most e.g. motivational quote, hotline numbers...\n",
        "    subject = \"Please read this.\"\n",
        "    body = \"\\n\\nIf you or someone you know is contemplating suicide, please reach out. You can find help at a National Suicide Prevention Lifeline\\n\\nUSA: 18002738255 US Crisis textline: 741741 text HOME\\n\\nUnited Kingdom: 116 123\\n\\nTrans Lifeline (877-565-8860)\\n\\nOthers: https://en.wikipedia.org/wiki/List_of_suicide_crisis_lines\\nhttps://suicidepreventionlifeline.org\\n\\nIf you wish to stop being monitored, reply with 'remove me'\"\n",
        "\n",
        "    # Choose what message to reply when bot receives 'monitor me' message\n",
        "    reply_start = \"Your submissions are now being monitored\\n\\nThis means that every post you make will be automatically classified.\\n\\nIf it is detected that you posted something suicidal, you will receive a message with an inspirational quote and support line numbers.\\n\\nReply with 'remove me' to stop being monitored.\"\n",
        "    # if already being monitored reply with:\n",
        "    reply_alrdy = \"You are already being monitored\\n\\nThis means that every post you make will be automatically classified.\\n\\nIf it is detected that you posted something suicidal, you will receive a message with an inspirational quote and support line numbers.\\n\\nIf you wish to stop being monitored, reply with 'remove me'.\"\n",
        "    # if bot receives 'remove me' message:\n",
        "    reply_stop = \"Monitoring has been stopped\\n\\nThis means that you will no longer receive messages from this bot.\\n\\nReply with 'monitor me' to start being monitored again.\"\n",
        "    # if redditor is not being monitored:\n",
        "    reply_nomonitor = \"You are not being monitored. Reply with 'monitor me' if you wish to be monitored.\\n\\nIf you choose to be monitored, every post you make will be automatically classified.\\n\\nIf it is detected that you posted something suicidal, you will receive a message with an inspirational quote and support line numbers.\"\n",
        "    # if bot receives unrecognised command:\n",
        "    reply_err = \"Unrecognised command. Please reply with either 'monitor me' to begin being monitored, or 'remove me' to stop being monitored.\\n\\nIf you choose to be monitored, every post you make will be automatically classified.\\n\\nIf it is detected that you posted something suicidal, you will receive a message with an inspirational quote and support line numbers.\"\n",
        "    ############################################################################################################\n",
        "    try:\n",
        "        if updating: # updating usernames\n",
        "            username_list = []\n",
        "            if os.path.isfile('usernames_to_monitor.txt'): # checks if file exists before reading it\n",
        "                with open('usernames_to_monitor.txt', 'r') as file:\n",
        "                    username_list = [line.strip() for line in file]\n",
        "                    username_list = [username.encode() for username in username_list]\n",
        "                    username_list = [fnet.decrypt(username).decode() for username in username_list]      \n",
        "            for message in reddit.inbox.unread(limit=None):\n",
        "                if 'monitor' in (message.body).lower():\n",
        "                    if message.author.name not in username_list:\n",
        "                        if 'removed' in username_list: # overwrites first instance of 'removed', with username\n",
        "                            for i in range(len(username_list)):\n",
        "                                if username_list[i] == 'removed':\n",
        "                                    username_list[i] = message.author.name\n",
        "                                    break\n",
        "                        else:\n",
        "                            username_list.append(message.author.name)\n",
        "                        message.reply(reply_start) \n",
        "                    else:\n",
        "                        message.reply(reply_alrdy)\n",
        "                elif 'remove' in (message.body).lower():\n",
        "                    if message.author.name in username_list:\n",
        "                        for i in range(len(username_list)):\n",
        "                            if username_list[i] == message.author.name:\n",
        "                                username_list[i] = 'removed'\n",
        "                                break\n",
        "                        message.reply(reply_stop)\n",
        "                    else:\n",
        "                        message.reply(reply_nomonitor)\n",
        "                else:\n",
        "                    message.reply(reply_err)\n",
        "                message.mark_read() # marks the message as read (as it has been replied to) so it won't be considered again\n",
        "            with open('usernames_to_monitor.txt', 'w') as file:\n",
        "                if username_list != []:\n",
        "                    encrypted_usernames = [fnet.encrypt(username.encode()) for username in username_list]\n",
        "                    encrypted_usernames = [username.decode() for username in encrypted_usernames]\n",
        "                    for username in encrypted_usernames:\n",
        "                        file.write('%s\\n' % username)\n",
        "            return username_list\n",
        "        ################################## COMMENT THIS IF TESTING POSTS ############################################################\n",
        "        else: # sending message\n",
        "            if not updating and not combined_df.empty:\n",
        "                for index in combined_df.index:\n",
        "                    if combined_df[4][index] == 1: # post was predicted suicidal\n",
        "                        quote_body = random.choice(inspirational_quotes) + body\n",
        "                        reddit.redditor(combined_df[1][index]).message(subject, quote_body) # message user whose post was suicidal\n",
        "                        print('Time taken for index:', index, (time.time()-combined_df[2][index])+(combined_df[2][index]-combined_df[2][0]))\n",
        "            return\n",
        "        #############################################################################################################################\n",
        "    except Exception as e:\n",
        "        print('bot Error is: ', e)\n",
        "        pass\n",
        "\n",
        "# preprocess the text column to be classified\n",
        "def preprocess(submission_df):\n",
        "    submission_df['postfixed'] = submission_df['post'].str.lower()\n",
        "    submission_df.replace('\\\\n', '', inplace=True, regex=True)\n",
        "    submission_df.replace('\\\\n\\\\n', '', inplace=True, regex=True)\n",
        "    submission_df['postfixed'].replace(to_replace='http\\S+', value='', inplace=True, regex=True) # remove URLs\n",
        "    submission_df['postfixed'].replace(to_replace='amp;\\S+', value='', inplace=True, regex=True) # remove formatting\n",
        "    submission_df['goodlemma'] = submission_df['postfixed'].apply(lambda x: \" \".join([y.lemma_ for y in nlp(x) if not y.is_stop and not y.is_punct]))\n",
        "    submission_df['goodlemma_most_important'] = submission_df['goodlemma'].apply(lambda x: \" \".join([str(y) for y in nlp(x) if str(y) in important_words]))\n",
        "    return submission_df\n",
        "\n",
        "# extracts data from generator and append it to a list\n",
        "def append(submission_data, submission):\n",
        "    subreddit = str(submission.subreddit)\n",
        "    author = str(submission.author)\n",
        "    date = int(submission.created_utc)\n",
        "    post = str(submission.title + \" \" + submission.selftext)\n",
        "    submission_data.append([subreddit, author, date, post])\n",
        "    return submission_data\n",
        "\n",
        "# extracts features to run model on\n",
        "def extract_features(submission_df_pp, tfidf):\n",
        "    tf_matrix = tfidf.transform(submission_df_pp['goodlemma'])\n",
        "    X = pd.DataFrame(tf_matrix.toarray())\n",
        "    return X\n",
        "\n",
        "# runs model on data to create predictions\n",
        "def classify(model, tfidf, submission_df_pp):\n",
        "    X = extract_features(submission_df_pp, tfidf)\n",
        "    y_pred = pd.DataFrame(model.predict(X), columns=['prediction'])\n",
        "    return y_pred\n",
        "    \n",
        "# can later expand arguments to an array so user can choose tfidf, word2vec or both\n",
        "def monitor(model, tfidf):\n",
        "    def iterable():  \n",
        "        submission_data = []\n",
        "        usernames = []\n",
        "        function_list = []\n",
        "        generator_list = []\n",
        "        while True:\n",
        "            try: \n",
        "                for generator in update_generators(usernames, function_list, generator_list):\n",
        "                    if generator is None: #username was removed from csv\n",
        "                        continue\n",
        "                    for submission in generator:\n",
        "                        if submission != None:\n",
        "                            submission_data = append(submission_data, submission)\n",
        "                        elif submission is None:\n",
        "                            break\n",
        "                        else:\n",
        "                            pass\n",
        "                    if submission_data != [] and (time.time() - submission_data[0][2] >= 5):\n",
        "                        submission_df = preprocess(pd.DataFrame.from_records(submission_data, columns=['subreddit', 'author', 'date', 'post']))\n",
        "                        prediction_df = classify(model, tfidf, submission_df)\n",
        "                        combined_df = log_submission(submission_df, prediction_df)\n",
        "                        bot(False, combined_df) # if first argument is False, then calls function in 'messaging suicidal users' mode\n",
        "                        submission_data = []\n",
        "            except Exception as e:\n",
        "                print('Iterator error is: ' + str(e))\n",
        "                pass\n",
        "    \n",
        "    def update_usernames(usernames):\n",
        "        try:\n",
        "            new_list = bot(True, None) # if first argument is True, then calls function in 'updating username' mode\n",
        "            if new_list == usernames: # no new changes\n",
        "                pass\n",
        "            elif new_list is None:\n",
        "                pass\n",
        "            else:\n",
        "                if len(new_list) > len(usernames):\n",
        "                    for j in range(len(usernames), len(new_list)):\n",
        "                        usernames.append(new_list[j])  \n",
        "                for i in range(len(usernames)):\n",
        "                    if new_list[i] == 'removed': # username removed from file\n",
        "                        usernames[i] = 'removed'\n",
        "                    elif new_list[i] != usernames[i]: # 'removed' overwritten with new user\n",
        "                        usernames[i] = new_list[i]\n",
        "                    else:\n",
        "                        pass\n",
        "            return usernames\n",
        "        except Exception as e:\n",
        "            print('update_usernames Error is: ' + str(e))\n",
        "            pass\n",
        "        \n",
        "    \n",
        "    def update_generators(usernames, function_list, generator_list):\n",
        "        try:\n",
        "            indices = [] # indices that we need to add or delete a stream for\n",
        "            tmp = usernames[:] # temporary array for storing original usernames list\n",
        "            new_usernames = update_usernames(usernames)\n",
        "            for i in range(len(new_usernames) - len(tmp)): # increases length of tmp, function_list, and generator_list to be equal to length of new_usernames\n",
        "                tmp.append(None)\n",
        "                function_list.append(None)\n",
        "                generator_list.append(None)\n",
        "            for j in range(len(new_usernames)): # make list of indexes where there were changes \n",
        "                if new_usernames[j] != tmp[j]:\n",
        "                    indices.append(j) \n",
        "            for x, username in enumerate(new_usernames): # will look like ['user', 'user2', 'removed', 'user4', 'newuser']\n",
        "                if x in indices:\n",
        "                    if username == 'removed': # username was removed from file\n",
        "                        function_list[x] = None\n",
        "                        generator_list[x] = None\n",
        "                    elif username != None and x < len(generator_list): # replaced 'removed' with a new user                    \n",
        "                        function_list[x] = (lambda x: reddit.redditor(f\"{username}\").stream.submissions(skip_existing=True, pause_after=-1)) # CHANGE SKIP EXISTING=FALSE TO GET 100 MOST RECENT POSTS\n",
        "                        generator_list[x] = function_list[x](username)\n",
        "                    else:\n",
        "                        pass\n",
        "            return generator_list\n",
        "        except Exception as e:\n",
        "            print('update_generators Error is: ' + str(e))\n",
        "            pass\n",
        "    return iterable()\n",
        "    \n",
        "monitor(model, tfidf) # start monitoring with chosen model and feature engineering method(s)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}